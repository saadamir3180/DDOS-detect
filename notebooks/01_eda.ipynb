{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Exploratory Data Analysis - CICDDoS2019 Dataset\n",
                "\n",
                "This notebook explores the CICDDoS2019 dataset to understand its structure, distribution, and characteristics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Add src to path\n",
                "sys.path.insert(0, '../src')\n",
                "\n",
                "from data_loader import DataLoader\n",
                "\n",
                "# Set style\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Path to dataset\n",
                "data_path = \"../data/raw/cicddos2019_dataset.csv\"\n",
                "\n",
                "# Get dataset info without loading full file\n",
                "loader = DataLoader(data_path)\n",
                "info = loader.get_data_info()\n",
                "\n",
                "print(\"Dataset Information:\")\n",
                "print(f\"Number of columns: {info['num_columns']}\")\n",
                "print(f\"File size: {info['file_size_mb']:.2f} MB\")\n",
                "print(f\"\\nColumns: {info['columns'][:10]}...\")  # Show first 10"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load a sample for exploration\n",
                "# Adjust sample_size based on your memory\n",
                "df = loader.load_data(sample_size=10000)\n",
                "\n",
                "print(f\"Loaded {len(df)} samples\")\n",
                "print(f\"Shape: {df.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Basic Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display first few rows\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data types\n",
                "df.dtypes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Basic statistics\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for missing values\n",
                "missing = df.isnull().sum()\n",
                "missing[missing > 0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Target Variable Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Assuming the target column is named 'Label' - adjust if different\n",
                "target_col = 'Label'  # Change this based on your dataset\n",
                "\n",
                "if target_col in df.columns:\n",
                "    # Class distribution\n",
                "    class_dist = df[target_col].value_counts()\n",
                "    print(\"Class Distribution:\")\n",
                "    print(class_dist)\n",
                "    print(f\"\\nClass proportions:\")\n",
                "    print(class_dist / len(df))\n",
                "else:\n",
                "    print(f\"Column '{target_col}' not found. Available columns:\")\n",
                "    print(df.columns.tolist())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize class distribution\n",
                "if target_col in df.columns:\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    df[target_col].value_counts().plot(kind='bar', color='skyblue', edgecolor='black')\n",
                "    plt.title('Class Distribution', fontsize=16)\n",
                "    plt.xlabel('Class', fontsize=12)\n",
                "    plt.ylabel('Count', fontsize=12)\n",
                "    plt.xticks(rotation=45, ha='right')\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Numeric features\n",
                "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
                "print(f\"Number of numeric features: {len(numeric_cols)}\")\n",
                "print(f\"Numeric features: {numeric_cols[:10]}...\")  # Show first 10"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Categorical features\n",
                "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
                "print(f\"Number of categorical features: {len(categorical_cols)}\")\n",
                "print(f\"Categorical features: {categorical_cols}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribution of first few numeric features\n",
                "if len(numeric_cols) > 0:\n",
                "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "    axes = axes.ravel()\n",
                "    \n",
                "    for idx, col in enumerate(numeric_cols[:6]):\n",
                "        df[col].hist(bins=50, ax=axes[idx], edgecolor='black')\n",
                "        axes[idx].set_title(col)\n",
                "        axes[idx].set_xlabel('Value')\n",
                "        axes[idx].set_ylabel('Frequency')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Correlation Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation matrix (for a subset of features)\n",
                "if len(numeric_cols) > 0:\n",
                "    # Select first 15 numeric features for correlation\n",
                "    subset_cols = numeric_cols[:15]\n",
                "    corr = df[subset_cols].corr()\n",
                "    \n",
                "    plt.figure(figsize=(12, 10))\n",
                "    sns.heatmap(corr, annot=False, cmap='coolwarm', center=0, \n",
                "                square=True, linewidths=0.5)\n",
                "    plt.title('Correlation Matrix (First 15 Features)', fontsize=16)\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save Insights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save EDA summary\n",
                "summary = {\n",
                "    'total_samples': len(df),\n",
                "    'total_features': len(df.columns),\n",
                "    'numeric_features': len(numeric_cols),\n",
                "    'categorical_features': len(categorical_cols),\n",
                "    'missing_values': df.isnull().sum().sum(),\n",
                "}\n",
                "\n",
                "if target_col in df.columns:\n",
                "    summary['class_distribution'] = df[target_col].value_counts().to_dict()\n",
                "\n",
                "print(\"\\nEDA Summary:\")\n",
                "for key, value in summary.items():\n",
                "    print(f\"{key}: {value}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "1. Proceed to `02_preprocessing.ipynb` for data cleaning and preparation\n",
                "2. Handle missing values and outliers\n",
                "3. Encode categorical features\n",
                "4. Scale numeric features"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}